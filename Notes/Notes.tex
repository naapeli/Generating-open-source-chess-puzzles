\documentclass[a4paper, 12pt]{article}

\usepackage{geometry}
\geometry{a4paper, margin=1in}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{graphicx}

\usepackage{lipsum}
\usepackage[svgnames]{xcolor}


\title{Generating open source chess puzzles - notes}
\author{Aatu Selkee}
\date{\today}

\begin{document}

\maketitle

\tableofcontents
\newpage

\section{Tokenization}

Tokenization v1

\begin{itemize}
    \item Board\begin{itemize}
        \item PNBRQKpnbrqk. = 13 tokens
    \end{itemize}
    \item Side to move\begin{itemize}
        \item wb = 1 tokens (b already counted)
    \end{itemize}
    \item Castling\begin{itemize}
        \item KQkq. = 0 tokens (already counted)
    \end{itemize}
    \item En passant\begin{itemize}
        \item abcdefgh = 7 tokens (b already counted)
        \item 12345678 = 8 tokens
        \item -. = 1 tokens (. already counted)
        \item = 16 tokens
    \end{itemize}
    \item Half move counter\begin{itemize}
        \item 0123456789 = 2 (0 and 9 new tokens)
    \end{itemize}
    \item Full move counter\begin{itemize}
        \item 0123456789 = 0 (already counted)
    \end{itemize}
\end{itemize}

= 32 tokens

Total tokens do not match the number of tokens in the paper 31 (the most obvious is that "-" might be replaced with a "."). The length of the produced string is also 76 instead of 77 for some reason. This tokenization feels bad, as e.g. side to move b is completely different to board b (black to move vs black bishop).

Tokenization v2 (my current choice): Length 76, number of tokens 48 (own tokens e.g. for black bishop and black to move)


\section{Model architecture}

What should be used, pre- or post-normalization (\cite{feng2025generatingcreativechesspuzzles} says post (it says that the llama papers use post, but I think they use pre), but \cite{touvron2023llamaopenefficientfoundation} and \cite{touvron2023llama2openfoundation} use pre-normalization to improve stability.)

\textcolor{red}{If we want some new experiments, we can find out what masking schedule produces the best results after supervised learning and then apply RL to that model.}

\section{RL}

\cite{feng2025generatingcreativechesspuzzles} did not use the masked diffusion for the RL, and it will probably be harder than with the autoregressive model.

Compute the log-probability of the models in the same way as with autoregressive models (sum the log probabilities of the chosen tokens). The model must be called $K$ times, where $K$ is the amount of tokens (the latter tokens depend on the previous tokens and teacher forcing is not possible I think?). Hence, the computational complexity is a lot higher with masked diffusion than with an autoregressive model. \textcolor{red}{I may be wrong based on algorithm 2 of \cite{ruoss2024amortizedplanninglargescaletransformers}, as we call the model as many times as we have discretized the range [0, 1].}

\textcolor{Green}{Computation of the log-probability is intractable for these diffusion models. Therefore, as it is needed in RL, we will use the ELBO as a replacement as was done in \cite{ou2025principledrldiffusionllms}. We should compute the ELBO in exactly the same way as in SFT (for a fen, sample $t$, compute $\alpha_t$ and mask with probability, then compute the ELBO as in the paper, finally apply RL with the log probabilities replaced with the negative ELBOs). This paper may also be useful \cite{rojas2025improvingreasoningdiffusionlanguage}.}

\bibliography{references.bib}
\bibliographystyle{ieeetr}

\end{document}

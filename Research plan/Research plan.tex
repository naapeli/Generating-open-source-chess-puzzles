\documentclass[a4paper, 12pt]{article}

\usepackage{geometry}
\geometry{a4paper, margin=1in}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{graphicx}

\usepackage{lipsum}
\usepackage{xcolor}


\title{Generating open source chess puzzles - research plan}
\author{Aatu Selkee}
\date{\today}

\begin{document}

\maketitle

\tableofcontents
\newpage

\section{Background}

Google DeepMind released a paper about generating novel chess puzzles with generative models at the end of October 2025 \cite{feng2025generatingcreativechesspuzzles}. They had a goal of training a generative model to output truly creative and novel outputs. Being a very difficult problem, they decided to start by considering a slightly smaller and easier problem in the field of chess. In this project, we aim to follow the approach by Google in \cite{feng2025generatingcreativechesspuzzles} to develop an open-source version of the generative model. We modify the approach in select parts for instance, by conditioning the output on specific themes. In the end, the final users will be able to select which type of puzzle they want to obtain. 


\section{Objectives}

The research goals of this project are:
\begin{itemize}
    \item Train a generative model that performs on par with the masked diffusion model in \cite{feng2025generatingcreativechesspuzzles} in terms of legality, uniqueness, counter intuitiveness and puzzle scores, as well as novelty metrics. Additionally, train a model that generates puzzles that are indistinguishable from human generated ones.
    \item Use the masked diffusion model for the whole pipeline (supervised and reinforcement learning). Masked diffusion is not used in the RL phase in \cite{feng2025generatingcreativechesspuzzles} and only the autoregressive model is used in RL.
    \item Condition the generation on the theme and the rating of a puzzle.
    \item Publish the model and perhaps build a website for people to use it.
\end{itemize}


\section{Methods}

Similarly to \cite{feng2025generatingcreativechesspuzzles}, we divide our training in two different stages, supervised training and reinforcement learning (RL). In the supervised stage, we use the Lichess puzzle dataset \cite{lichesspuzzledatabase} as the training set, which contains fen-strings, difficulty ratings and theming of different positions. We tokenize the fen-strings using the approach in \cite{ruoss2024amortizedplanninglargescaletransformers} and the themes by one-hot encoding (multiple themes can potentially be present in one puzzle). In the future, we may consider using a BERT language model to understand the themes as complete sentences, but at first, the themes are not part of sentances. In total there are 66 different themes in the dataset. In addition to the themes, our model will condition on the difficulty rating of the puzzle.

In the supervised phase, we train a masked diffusion model described in \cite{shi2025simplifiedgeneralizedmaskeddiffusion}. We use similar hyperparameters as the one used in \cite{feng2025generatingcreativechesspuzzles}, which result in a model with around 200M parameters in total. After supervised training, we evaluate the masked diffusion model with the legality, uniqueness, counter intuitiveness, puzzle and novelty metrics to compare with the final model after RL training.

In the reinforcement learning phase, we follow exactly the same procedure as in \cite{feng2025generatingcreativechesspuzzles}, but use the masked diffusion model instead of the autoregressive model. In \cite{feng2025generatingcreativechesspuzzles}, the authors chose the autoregressive model based on the supervised phase and only used it for the RL. We use critic-free PPO as the optimization method and the same reward structure as in \cite{feng2025generatingcreativechesspuzzles}. We may also experiment with additional rewards given based on the generated puzzle matching the theme it was conditioned on.

After reinforcement learning, we compare the legality, uniqueness, counter intuitiveness, puzzle and novelty metrics with the ones before RL as well as the ones in the paper. In addition, we will perform a human study, where we show random puzzles from the Lichess puzzle dataset \cite{lichesspuzzledatabase} and the ones we generated to human experts. We will let them rank the puzzles in realism, difficulty, creativity, fun and counter intuitiveness in scale from 0 (poor) to 3 (perfect) as in \cite{feng2025generatingcreativechesspuzzles}. These metrics can be compared with the ones presented in \cite{feng2025generatingcreativechesspuzzles}. Additionally, we will let the experts guess if the puzzle was generated by our model or not, and compare if the theme and the difficulty rating match the puzzle itself.


\section{Timeline}

As the authors of \cite{feng2025generatingcreativechesspuzzles} had trouble with the stability of the RL algorithm, we expect the RL phase to take the most amount of time. Hence we allocate more time for the RL than for the supervised phase. The timeline will look something like the following:

\begin{itemize}
    \item January: \begin{itemize}
        \item All practicalities
        \item Experiment with the dataset
        \item Implement dataloaders and split the test set
        \item Implement the tokenization
        \item Implement the model
        \item Start working on the supervised phase
    \end{itemize}
    \item February: \begin{itemize}
        \item Supervised model finished
        \item Generate puzzles with the supervised model
        \item Compute the chosen metrics
        \item Start working on the RL phase
    \end{itemize}
    \item March: \begin{itemize}
        \item Continue working on the RL
        \item Contact chess experts for the experiment
    \end{itemize}
    \item April: \begin{itemize}
        \item Finish the RL training
        \item Generate new puzzles and compute the metrics
        \item Contact chess experts for the experiment
    \end{itemize}
    \item May: \begin{itemize}
        \item Do the experiment with the experts
        \item Start writing the paper and the thesis
    \end{itemize}
    \item June: \begin{itemize}
        \item Finish the thesis and send the publication for review
        \item Build a website where people can use the model or publish the model on Huggingface or similar
    \end{itemize}
\end{itemize}


\section{Results}

The preliminary results after supervised training the masked diffusion model are shown in the table below.

% \begin{table}[h]
%     \centering
%     \caption{The proportion of positions satisfying a criterion. An average is taken over 1000 generated positions from the model or 1000 randomly sampled positions from the Lichess Puzzle dataset. The values in the parenthesis are the corresponding values in \cite{feng2025generatingcreativechesspuzzles}.}
%     \begin{tabular}{|c|c|c|}
%         \hline
%         & Lichess puzzles & Masked Diffusion \\
%         \hline
%         Legal & 100\% & 96.8\% (99.72\%)\\
%         \hline
%         Unique & 81.7\% (95.25\%) & 9.67\% (30.89\%)\\
%         \hline
%         Counter-intuitive & 4.3\% (2.25\%) & 23.7\% (1.11\%)\\
%         \hline
%         Puzzle & 4.1\% (2.14\%) & 0.1\% (0.34\%)\\
%         \hline
%     \end{tabular}
% \end{table}

\begin{table}[h]
    \centering
    \caption{The proportion of positions satisfying a criterion. An average is taken over 1000 generated positions from the model or 1000 randomly sampled positions from the Lichess Puzzle dataset. The values in the parenthesis are the corresponding values in \cite{feng2025generatingcreativechesspuzzles}.}
    \begin{tabular}{|c|c|c|}
        \hline
        & Lichess puzzles & Masked Diffusion \\
        \hline
        Legal & 100\% & 96.8\% (99.72\%)\\
        \hline
        Unique & 81.4\% (95.25\%) & 9.71\% (30.89\%)\\
        \hline
        Counter-intuitive & 5.0\% (2.25\%) & 1.1\% (1.11\%)\\
        \hline
        Puzzle & 4.1\% (2.14\%) & 0.1\% (0.34\%)\\
        \hline
    \end{tabular}
\end{table}

\bibliography{references.bib}
\bibliographystyle{ieeetr}

\end{document}
